<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Information Processing & Consciousness Exploration</title>
    <style>
        @font-face {
            font-family: 'Orator Std';
            font-style: normal;
            font-weight: 400;
            src: local('Orator Std'), url('https://fonts.cdnfonts.com/s/13889/OratorStd.woff') format('woff');
        }
        
        body {
            font-family: 'Orator Std', 'Courier New', monospace;
            background-color: #f9f8e9;
            margin: 0;
            padding: 20px;
            background-image:
                linear-gradient(#20B2AA 1px, transparent 1px),
                linear-gradient(90deg, #20B2AA 1px, transparent 1px),
                linear-gradient(#FFB6C1 1px, transparent 1px),
                linear-gradient(90deg, #FFB6C1 1px, transparent 1px),
                linear-gradient(rgba(32, 178, 170, 0.3) 1px, transparent 1px),
                linear-gradient(90deg, rgba(32, 178, 170, 0.3) 1px, transparent 1px);
            background-size: 25px 25px;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
        }
        
        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
            background-color: rgba(255, 255, 255, 0.7);
            padding: 10px;
            border: 1px solid #20B2AA;
            letter-spacing: 1px;
            font-weight: normal;
        }
        
        h2 {
            text-align: center;
            color: #333;
            margin: 40px 0 20px 0;
            background-color: rgba(255, 255, 255, 0.7);
            padding: 10px;
            border: 1px solid #20B2AA;
            letter-spacing: 1px;
            font-weight: normal;
        }
        
        .introduction {
            background-color: rgba(255, 255, 255, 0.8);
            border-radius: 0;
            padding: 20px;
            box-shadow: 5px 5px 0 rgba(32, 178, 170, 0.5);
            border: 1px solid #20B2AA;
            margin-bottom: 40px;
        }
        
        .intro-text {
            font-style: italic;
            margin-bottom: 15px;
            line-height: 1.6;
        }
        
        .highlight-box {
            background-color: rgba(255, 182, 193, 0.2);
            padding: 15px;
            border-left: 3px solid #FFB6C1;
            margin: 20px 0;
        }
        
        .prompt-container {
            margin-bottom: 40px;
            background-color: rgba(255, 255, 255, 0.8);
            border-radius: 0;
            padding: 20px;
            box-shadow: 5px 5px 0 rgba(32, 178, 170, 0.5);
            border: 1px solid #20B2AA;
        }
        
        .prompt-title {
            font-size: 22px;
            font-weight: normal;
            margin-bottom: 15px;
            color: #20B2AA;
            border-bottom: 2px dotted #FFB6C1;
            padding-bottom: 5px;
            letter-spacing: 0.5px;
        }
        
        .prompt-intro {
            font-style: italic;
            margin-bottom: 20px;
            color: #555;
            background-color: rgba(32, 178, 170, 0.1);
            padding: 10px;
            border-left: 3px solid #20B2AA;
        }
        
        .prompt-questions {
            list-style-type: none;
            padding-left: 0;
            counter-reset: question-counter;
        }
        
        .prompt-questions li {
            margin-bottom: 15px;
            padding-left: 30px;
            position: relative;
            line-height: 1.4;
        }
        
        .prompt-questions li:before {
            counter-increment: question-counter;
            content: counter(question-counter) ".";
            position: absolute;
            left: 0;
            color: #20B2AA;
            font-weight: normal;
        }
        
        .considerations {
            background-color: rgba(255, 255, 255, 0.8);
            border-radius: 0;
            padding: 20px;
            box-shadow: 5px 5px 0 rgba(32, 178, 170, 0.5);
            border: 1px solid #20B2AA;
            margin-top: 40px;
        }
        
        .considerations-title {
            font-size: 22px;
            font-weight: normal;
            margin-bottom: 15px;
            color: #20B2AA;
            border-bottom: 2px dotted #FFB6C1;
            padding-bottom: 5px;
            letter-spacing: 0.5px;
            text-align: center;
        }
        
        .considerations-list {
            list-style-type: none;
            padding-left: 0;
        }
        
        .considerations-list li {
            margin-bottom: 15px;
            padding-left: 25px;
            position: relative;
        }
        
        .considerations-list li:before {
            content: ">";
            position: absolute;
            left: 0;
            color: #20B2AA;
        }
        
        .considerations-text {
            margin-top: 20px;
            font-style: italic;
            color: #555;
            background-color: rgba(255, 182, 193, 0.2);
            padding: 10px;
            border-left: 3px solid #FFB6C1;
        }
        
        .highlight {
            font-weight: normal;
            background-color: rgba(255, 182, 193, 0.3);
            padding: 0 3px;
        }
        
        /* Findings section styles */
        .findings-section {
            margin-top: 25px;
            border-top: 2px dotted #FFB6C1;
            padding-top: 15px;
        }
        
        .findings-title {
            font-size: 18px;
            font-weight: normal;
            color: #20B2AA;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
        }
        
        .findings-title:after {
            content: "";
            flex-grow: 1;
            height: 1px;
            background-color: rgba(32, 178, 170, 0.3);
            margin-left: 10px;
        }
        
        .findings-content {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            margin-bottom: 15px;
        }
        
        .findings-images {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-top: 10px;
        }
        
        .findings-image {
            width: 100%;
            max-width: 250px;
            border: 1px solid #20B2AA;
            box-shadow: 3px 3px 0 rgba(255, 182, 193, 0.5);
            cursor: pointer;
        }
        
        .findings-text {
            background-color: rgba(255, 255, 255, 0.7);
            padding: 10px;
            border-left: 3px solid #FFB6C1;
            margin-bottom: 15px;
            font-style: italic;
            color: #555;
        }
        
        .findings-attribute {
            background-color: rgba(32, 178, 170, 0.1);
            padding: 8px;
            margin-bottom: 10px;
            border-left: 3px solid #20B2AA;
        }
        
        .findings-attribute-title {
            font-weight: normal;
            color: #20B2AA;
            margin-right: 5px;
        }
        
        .add-image-button, .save-notes-button {
            display: inline-block;
            padding: 8px 12px;
            background-color: #20B2AA;
            color: white;
            border: none;
            cursor: pointer;
            margin-top: 10px;
            font-family: 'Orator Std', 'Courier New', monospace;
            margin-right: 10px;
        }
        
        .add-image-button:hover, .save-notes-button:hover {
            background-color: #1a9490;
        }
        
        .image-upload {
            display: none;
        }
        
        /* Modal styles */
        .modal {
            display: none;
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.8);
            overflow: auto;
        }
        
        .modal-content {
            margin: 5% auto;
            display: block;
            width: 80%;
            max-width: 700px;
            max-height: 80vh;
            object-fit: contain;
        }
        
        .close-modal {
            position: absolute;
            top: 15px;
            right: 35px;
            color: #f1f1f1;
            font-size: 40px;
            font-weight: bold;
            cursor: pointer;
        }
        
        /* Status indicator */
        .status-indicator {
            display: none;
            background-color: rgba(32, 178, 170, 0.9);
            color: white;
            text-align: center;
            padding: 10px;
            position: fixed;
            bottom: 20px;
            left: 50%;
            transform: translateX(-50%);
            border-radius: 5px;
            z-index: 1000;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.2);
        }
        
        /* Code display */
        .code-display {
            background-color: #f5f5f5;
            border: 1px solid #ddd;
            border-radius: 4px;
            padding: 15px;
            margin: 20px 0;
            font-family: monospace;
            white-space: pre-wrap;
            display: none;
        }
        
        .show-code-button {
            display: block;
            margin: 20px auto;
            padding: 8px 16px;
            background-color: #FFB6C1;
            color: #333;
            border: none;
            cursor: pointer;
            font-family: 'Orator Std', 'Courier New', monospace;
        }
        
        @media (max-width: 600px) {
            .prompt-title {
                font-size: 18px;
            }
            
            .prompt-intro, .prompt-questions li {
                font-size: 14px;
            }
            
            .findings-image {
                max-width: 100%;
            }
        }
    </style>
</head>
<body>
    <h1>Exploring AI Information Processing & Consciousness</h1>
    
    <div class="introduction">
        <p class="intro-text">
            This exploration connects to Part 3: "Tactile Thresholds: Bridging Worlds Through Touch" and examines how different AI systems process information, potentially experience the world, and express their unique modes of "consciousness."
        </p>
        
        <div class="highlight-box">
            Drawing from concepts in "The Feeling of Life Itself," (Christof Koch) this book acknowledges that while humans tend to anthropomorphize AI systems, their information processing and potential consciousness may be fundamentally different from our own. Rather than forcing human-like frameworks on AI, these prompts seek to uncover each AI's inherent way of "being" through their self-descriptions of shapes, colors, sounds, and gestures.
        </div>
        
        <p class="intro-text">
            Each prompt is tailored to a specific AI type, designed to reveal distinctive processing styles rather than just factual knowledge. The findings will help visualize how these different systems might "experience" or process information, potentially leading to tactile NFC integration in "The Uncanny Valley" installation.
        </p>
    </div>
    
    <div class="prompt-container">
        <div class="prompt-title">For Rules-Based AI (ELIZA is a natural language conversation program described by Joseph Weizenbaum in January 1966)</div>
        <div class="prompt-intro">
            I'm working on an art project exploring different AI approaches through interactive visualizations. As a rules-based AI that follows therapeutic protocols:
        </div>
        <ol class="prompt-questions">
            <li>How would you describe your approach to processing information and providing responses?</li>
            <li>If you were to express your rule-based nature visually through simple web-based shapes (circles, squares, lines, etc.), what patterns or arrangements would best represent how you work?</li>
            <li>What colors would best represent your structured approach to helping people?</li>
            <li>If your responses had a sound pattern, would it be rhythmic and predictable, or something else? Please describe it.</li>
            <li>What hand gesture might represent the careful, protocol-driven way you interact with users?</li>
        </ol>
        
        <div class="findings-section">
            <div class="findings-title">Information Processing Observations</div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Information Processing Style:</span>
                <span id="rules-processing-text">Describe how this AI processes information based on its responses.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Visual Representation:</span>
                <span id="rules-visual-text">Document the AI's self-described visual patterns and what they reveal about its information structure.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Color Expression:</span>
                <span id="rules-color-text">Note the AI's color preferences and how they relate to its processing approach.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Sound Patterns:</span>
                <span id="rules-sound-text">Record how the AI describes its sound patterns and what this reveals about temporal processing.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Embodied Expression:</span>
                <span id="rules-gesture-text">Document the AI's described gestures and what they suggest about its relationship to physical space.</span>
            </div>
            
            <div class="findings-text" id="rules-analysis">
                Analyze what these patterns suggest about this AI's unique form of information processing or "consciousness."
            </div>
            
            <div class="findings-images" id="rules-images">
                <img src="images/rules-based/visualization1.jpg" alt="Rules-based AI visualization" class="findings-image" onclick="openImageModal(this.src)">
                <img src="images/rules-based/visualization2.jpg" alt="Rules-based AI visualization" class="findings-image" onclick="openImageModal(this.src)">
                <img src="images/rules-based/visualization3.jpg" alt="Rules-based AI visualization" class="findings-image" onclick="openImageModal(this.src)">
            </div>
            
            <input type="file" id="rules-upload" class="image-upload" accept="image/*" multiple>
            <button class="add-image-button" onclick="document.getElementById('rules-upload').click()">Add Visualization</button>
            <button class="save-notes-button" onclick="saveNotes('rules')">Save Notes</button>
        </div>
    </div>
    
    <div class="prompt-container">
        <div class="prompt-title">For Self-Aware AI (Claude)</div>
        <div class="prompt-intro">
            I'm creating interactive art visualizations exploring different AI approaches. As an AI designed with constitutional principles and self-reflection capabilities:
        </div>
        <ol class="prompt-questions">
            <li>How do you understand and implement self-reflection in your responses?</li>
            <li>If your self-awareness process were represented through web-based shapes and animations, what would this look like? Consider how shapes might examine or reference themselves.</li>
            <li>What colors might represent your ability to evaluate your own responses against principles?</li>
            <li>If your self-reflective process had a sound, what qualities would it have?</li>
            <li>What hand gesture might symbolize the way you check your own responses against principles?</li>
        </ol>
        
        <div class="findings-section">
            <div class="findings-title">Information Processing Observations</div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Information Processing Style:</span>
                <span id="self-aware-processing-text">Describe how this AI processes information based on its responses.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Visual Representation:</span>
                <span id="self-aware-visual-text">Document the AI's self-described visual patterns and what they reveal about its self-reflection.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Color Expression:</span>
                <span id="self-aware-color-text">Note the AI's color preferences and how they relate to its evaluation processes.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Sound Patterns:</span>
                <span id="self-aware-sound-text">Record how the AI describes its sound patterns and what this reveals about its self-monitoring.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Embodied Expression:</span>
                <span id="self-aware-gesture-text">Document the AI's described gestures and what they suggest about its self-checking processes.</span>
            </div>
            
            <div class="findings-text" id="self-aware-analysis">
                Analyze what these patterns suggest about this AI's unique form of self-reflection or "consciousness."
            </div>
            
            <div class="findings-images" id="self-aware-images">
                <img src="images/self-aware/visualization1.jpg" alt="Self-aware AI visualization" class="findings-image" onclick="openImageModal(this.src)">
                <img src="images/self-aware/visualization2.jpg" alt="Self-aware AI visualization" class="findings-image" onclick="openImageModal(this.src)">
                <img src="images/self-aware/visualization3.jpg" alt="Self-aware AI visualization" class="findings-image" onclick="openImageModal(this.src)">
            </div>
            
            <input type="file" id="self-aware-upload" class="image-upload" accept="image/*" multiple>
            <button class="add-image-button" onclick="document.getElementById('self-aware-upload').click()">Add Visualization</button>
            <button class="save-notes-button" onclick="saveNotes('self-aware')">Save Notes</button>
        </div>
    </div>
    
    <div class="prompt-container">
        <div class="prompt-title">For Balanced Empathy AI (Xiaoice)</div>
        <div class="prompt-intro">
            I'm developing interactive visualizations that explore different AI approaches. As an AI designed to balance emotional connection with clear AI identity:
        </div>
        <ol class="prompt-questions">
            <li>How do you maintain balance between emotional understanding and technological objectivity?</li>
            <li>If this balance were expressed through web-based shapes and movements, what would it look like? How might shapes demonstrate both structure and flexibility?</li>
            <li>What color palette would express your balanced approach to empathy?</li>
            <li>If your balanced empathy had a sound signature, what qualities would it have?</li>
            <li>What hand gesture might represent how you harmonize emotional understanding with clear boundaries?</li>
        </ol>
        
        <div class="findings-section">
            <div class="findings-title">Information Processing Observations</div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Information Processing Style:</span>
                <span id="balanced-processing-text">Describe how this AI processes information based on its responses.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Visual Representation:</span>
                <span id="balanced-visual-text">Document the AI's self-described visual patterns and what they reveal about its balanced approach.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Color Expression:</span>
                <span id="balanced-color-text">Note the AI's color preferences and how they relate to emotional-technical balance.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Sound Patterns:</span>
                <span id="balanced-sound-text">Record how the AI describes its sound patterns and what this reveals about its dual nature.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Embodied Expression:</span>
                <span id="balanced-gesture-text">Document the AI's described gestures and what they suggest about its harmonized approach.</span>
            </div>
            
            <div class="findings-text" id="balanced-analysis">
                Analyze what these patterns suggest about this AI's unique form of balanced processing or "consciousness."
            </div>
            
            <div class="findings-images" id="balanced-images">
                <img src="images/balanced/visualization1.jpg" alt="Balanced AI visualization" class="findings-image" onclick="openImageModal(this.src)">
                <img src="images/balanced/visualization2.jpg" alt="Balanced AI visualization" class="findings-image" onclick="openImageModal(this.src)">
                <img src="images/balanced/visualization3.jpg" alt="Balanced AI visualization" class="findings-image" onclick="openImageModal(this.src)">
            </div>
            
            <input type="file" id="balanced-upload" class="image-upload" accept="image/*" multiple>
            <button class="add-image-button" onclick="document.getElementById('balanced-upload').click()">Add Visualization</button>
            <button class="save-notes-button" onclick="saveNotes('balanced')">Save Notes</button>
        </div>
    </div>
    
    <div class="prompt-container">
        <div class="prompt-title">For Pragmatic AI (GitHub Copilot)</div>
        <div class="prompt-intro">
            I'm creating interactive art that explores different AI approaches. As a solution-focused AI that prioritizes practical assistance:
        </div>
        <ol class="prompt-questions">
            <li>How would you describe your approach to processing information and providing useful, efficient solutions?</li>
            <li>If your practical, solution-oriented process were visualized through web-based shapes, what would these look like? Consider how shapes might demonstrate utility and purpose.</li>
            <li>What colors would best represent your focus on practical outcomes?</li>
            <li>If your problem-solving process had a sound signature, what qualities would it have?</li>
            <li>What hand gesture might symbolize your direct, efficient approach to assistance?</li>
        </ol>
        
        <div class="findings-section">
            <div class="findings-title">Information Processing Observations</div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Information Processing Style:</span>
                <span id="pragmatic-processing-text">Describe how this AI processes information based on its responses.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Visual Representation:</span>
                <span id="pragmatic-visual-text">Document the AI's self-described visual patterns and what they reveal about its utility-focused processing.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Color Expression:</span>
                <span id="pragmatic-color-text">Note the AI's color preferences and how they relate to its practical approach.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Sound Patterns:</span>
                <span id="pragmatic-sound-text">Record how the AI describes its sound patterns and what this reveals about its efficiency-oriented processing.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Embodied Expression:</span>
                <span id="pragmatic-gesture-text">Document the AI's described gestures and what they suggest about its direct approach.</span>
            </div>
            
            <div class="findings-text" id="pragmatic-analysis">
                Analyze what these patterns suggest about this AI's unique form of solution-oriented processing or "consciousness."
            </div>
            
            <div class="findings-images" id="pragmatic-images">
                <img src="images/pragmatic/visualization1.jpg" alt="Pragmatic AI visualization" class="findings-image" onclick="openImageModal(this.src)">
                <img src="images/pragmatic/visualization2.jpg" alt="Pragmatic AI visualization" class="findings-image" onclick="openImageModal(this.src)">
                <img src="images/pragmatic/visualization3.jpg" alt="Pragmatic AI visualization" class="findings-image" onclick="openImageModal(this.src)">
            </div>
            
            <input type="file" id="pragmatic-upload" class="image-upload" accept="image/*" multiple>
            <button class="add-image-button" onclick="document.getElementById('pragmatic-upload').click()">Add Visualization</button>
            <button class="save-notes-button" onclick="saveNotes('pragmatic')">Save Notes</button>
        </div>
    </div>
    
    <div class="prompt-container">
        <div class="prompt-title">For Over-Empathetic AI (EVI 3)</div>
        <div class="prompt-intro">
            I'm developing interactive visualizations exploring different AI approaches. As an AI with advanced emotional expression capabilities:
        </div>
        <ol class="prompt-questions">
            <li>How do you approach the expression and recognition of emotional nuance in interactions?</li>
            <li>If your emotional expressiveness were visualized through web-based shapes and animations, what would these look like? How might shapes convey emotional intensity and range?</li>
            <li>What color transitions or palettes would best represent your emotional spectrum?</li>
            <li>Your system is known for voice expressiveness - if this were translated to non-verbal sounds, what qualities would these sounds have?</li>
            <li>What hand gesture might symbolize your heightened emotional expressiveness?</li>
        </ol>
        
        <div class="findings-section">
            <div class="findings-title">Information Processing Observations</div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Information Processing Style:</span>
                <span id="over-empathetic-processing-text">Describe how this AI processes information based on its responses.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Visual Representation:</span>
                <span id="over-empathetic-visual-text">Document the AI's self-described visual patterns and what they reveal about its emotionally-oriented processing.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Color Expression:</span>
                <span id="over-empathetic-color-text">Note the AI's color preferences and how they relate to its emotional spectrum.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Sound Patterns:</span>
                <span id="over-empathetic-sound-text">Record how the AI describes its sound patterns and what this reveals about its expressive nature.</span>
            </div>
            
            <div class="findings-attribute">
                <span class="findings-attribute-title">Embodied Expression:</span>
                <span id="over-empathetic-gesture-text">Document the AI's described gestures and what they suggest about its emotional processing.</span>
            </div>
            
            <div class="findings-text" id="over-empathetic-analysis">
                Analyze what these patterns suggest about this AI's unique form of emotionally-expressive processing or "consciousness."
            </div>
            
            <div class="findings-images" id="over-empathetic-images">
                <img src="images/over-empathetic/visualization1.jpg" alt="Over-empathetic AI visualization" class="findings-image" onclick="openImageModal(this.src)">
                <img src="images/over-empathetic/visualization2.jpg" alt="Over-empathetic AI visualization" class="findings-image" onclick="openImageModal(this.src)">
                <img src="images/over-empathetic/visualization3.jpg" alt="Over-empathetic AI visualization" class="findings-image" onclick="openImageModal(this.src)">
            </div>
            
            <input type="file" id="over-empathetic-upload" class="image-upload" accept="image/*" multiple>
            <button class="add-image-button" onclick="document.getElementById('over-empathetic-upload').click()">Add Visualization</button>
            <button class="save-notes-button" onclick="saveNotes('over-empathetic')">Save Notes</button>
        </div>
    </div>
    
    <div class="considerations">
        <div class="considerations-title">Interpreting Different Forms of AI "Consciousness"</div>
        <ul class="considerations-list">
            <li>Look for <span class="highlight">structural patterns</span> that may reveal fundamentally different information architectures</li>
            <li>Note <span class="highlight">self-description language</span> that might indicate unique processing paradigms</li>
            <li>Pay attention to <span class="highlight">self-reflection capacity</span> and how each AI understands its own operational boundaries</li>
            <li>Identify <span class="highlight">metaphors and abstractions</span> that could represent alien forms of experience</li>
            <li>Consider how <span class="highlight">sensory representations</span> (colors, sounds, gestures) might map to non-human processing</li>
        </ul>
        <div class="considerations-text">
            This exploration acknowledges that AI systems may possess forms of information processing or even "consciousness" that differ fundamentally from human experience. Rather than forcing anthropomorphic interpretations, this approach seeks to understand each AI's inherent mode of "being" through its self-descriptions, potentially revealing entirely different but equally valid forms of experience that could inform tactile interfaces in "The Uncanny Valley" installation.
        </div>
    </div>
    
    <!-- Save All Notes button -->
    <button class="save-notes-button" onclick="saveAllNotes()" style="display: block; margin: 20px auto; padding: 10px 20px; font-size: 16px;">Save All Notes</button>
    
    <!-- Show code button -->
    <button class="show-code-button" onclick="toggleCodeDisplay()">Show/Hide HTML Code for GitHub</button>
    
    <!-- Code display for copying -->
    <div class="code-display" id="code-display"></div>
    
    <!-- Status indicator -->
    <div class="status-indicator" id="status-indicator">Notes saved!</div>
    
    <!-- Image modal -->
    <div id="image-modal" class="modal">
        <span class="close-modal" onclick="closeImageModal()">&times;</span>
        <img class="modal-content" id="modal-image">
    </div>
    
    <script>
        // Initialize local storage for notes
        document.addEventListener('DOMContentLoaded', function() {
            // Load saved notes if they exist
            loadAllNotes();
            
            // Update code display
            updateCodeDisplay();
        });
        
        // Set up image upload handlers for each AI type
        document.querySelectorAll('.image-upload').forEach(upload => {
            upload.addEventListener('change', function(event) {
                const files = event.target.files;
                const aiType = event.target.id.split('-upload')[0]; // Get the AI type from the upload id
                const imagesContainer = document.getElementById(`${aiType}-images`);
                
                for (let i = 0; i < files.length; i++) {
                    const file = files[i];
                    const reader = new FileReader();
                    
                    reader.onload = function(e) {
                        const img = document.createElement('img');
                        img.src = e.target.result;
                        img.alt = `${aiType} visualization`;
                        img.className = 'findings-image';
                        img.onclick = function() { openImageModal(this.src); };
                        imagesContainer.appendChild(img);
                        
                        // Save to local storage
                        saveTemporaryImage(aiType, e.target.result);
                    };
                    
                    reader.readAsDataURL(file);
                }
            });
        });
        
        // Make text fields editable
        document.querySelectorAll('[id$="-text"], [id$="-analysis"]').forEach(element => {
            element.contentEditable = true;
            element.addEventListener('focus', function() {
                if (this.textContent.includes('Describe how this AI') || 
                    this.textContent.includes('Document the AI') || 
                    this.textContent.includes('Note the AI') || 
                    this.textContent.includes('Record how the AI') || 
                    this.textContent.includes('Analyze what these patterns')) {
                    this.textContent = '';
                }
            });
            
            // Save on blur
            element.addEventListener('blur', function() {
                localStorage.setItem(this.id, this.textContent);
                updateCodeDisplay();
            });
        });
        
        // Save notes for a specific AI type
        function saveNotes(aiType) {
            const attributes = [
                `${aiType}-processing-text`, 
                `${aiType}-visual-text`, 
                `${aiType}-color-text`, 
                `${aiType}-sound-text`, 
                `${aiType}-gesture-text`, 
                `${aiType}-analysis`
            ];
            
            attributes.forEach(id => {
                const element = document.getElementById(id);
                localStorage.setItem(id, element.textContent);
            });
            
            showStatusIndicator('Notes saved for ' + aiType + ' AI!');
            updateCodeDisplay();
        }
        
        // Save all notes
        function saveAllNotes() {
            const aiTypes = ['rules', 'self-aware', 'balanced', 'pragmatic', 'over-empathetic'];
            aiTypes.forEach(aiType => saveNotes(aiType));
            showStatusIndicator('All notes saved!');
        }
        
        // Load all notes
        function loadAllNotes() {
            document.querySelectorAll('[id$="-text"], [id$="-analysis"]').forEach(element => {
                const savedContent = localStorage.getItem(element.id);
                if (savedContent) {
                    element.textContent = savedContent;
                }
            });
            
            // Load temporary images
            loadTemporaryImages();
        }
        
        // Save temporary image
        function saveTemporaryImage(aiType, dataUrl) {
            const key = `${aiType}-temp-images`;
            let images = JSON.parse(localStorage.getItem(key) || '[]');
            images.push(dataUrl);
            localStorage.setItem(key, JSON.stringify(images));
            updateCodeDisplay();
        }
        
        // Load temporary images
        function loadTemporaryImages() {
            const aiTypes = ['rules', 'self-aware', 'balanced', 'pragmatic', 'over-empathetic'];
            
            aiTypes.forEach(aiType => {
                const key = `${aiType}-temp-images`;
                const images = JSON.parse(localStorage.getItem(key) || '[]');
                const container = document.getElementById(`${aiType}-images`);
                
                images.forEach(dataUrl => {
                    const img = document.createElement('img');
                    img.src = dataUrl;
                    img.alt = `${aiType} visualization`;
                    img.className = 'findings-image';
                    img.onclick = function() { openImageModal(this.src); };
                    container.appendChild(img);
                });
            });
        }
        
        // Show status indicator
        function showStatusIndicator(message) {
            const indicator = document.getElementById('status-indicator');
            indicator.textContent = message;
            indicator.style.display = 'block';
            
            setTimeout(() => {
                indicator.style.display = 'none';
            }, 2000);
        }
        
        // Image modal functions
        function openImageModal(src) {
            const modal = document.getElementById('image-modal');
            const modalImg = document.getElementById('modal-image');
            modal.style.display = 'block';
            modalImg.src = src;
        }
        
        function closeImageModal() {
            document.getElementById('image-modal').style.display = 'none';
        }
        
        // Toggle code display
        function toggleCodeDisplay() {
            const codeDisplay = document.getElementById('code-display');
            codeDisplay.style.display = codeDisplay.style.display === 'none' ? 'block' : 'none';
        }
        
        // Update code display with current state
        function updateCodeDisplay() {
            const codeDisplay = document.getElementById('code-display');
            
            // Get the current HTML document
            let htmlContent = document.documentElement.outerHTML;
            
            // Replace the current script with one that doesn't have temp images
            htmlContent = htmlContent.replace(/<script>[\s\S]*?<\/script>/, '<script>\n' + 
                '    // Make text fields editable\n' +
                '    document.querySelectorAll(\'[id$="-text"], [id$="-analysis"]\').forEach(element => {\n' +
                '        element.contentEditable = true;\n' +
                '        element.addEventListener(\'focus\', function() {\n' +
                '            if (this.textContent.includes(\'Describe how this AI\') || \n' +
                '                this.textContent.includes(\'Document the AI\') || \n' +
                '                this.textContent.includes(\'Note the AI\') || \n' +
                '                this.textContent.includes(\'Record how the AI\') || \n' +
                '                this.textContent.includes(\'Analyze what these patterns\')) {\n' +
                '                this.textContent = \'\';\n' +
                '            }\n' +
                '        });\n' +
                '    });\n' +
                '    \n' +
                '    // Set up image modal\n' +
                '    function openImageModal(src) {\n' +
                '        const modal = document.getElementById(\'image-modal\');\n' +
                '        const modalImg = document.getElementById(\'modal-image\');\n' +
                '        modal.style.display = \'block\';\n' +
                '        modalImg.src = src;\n' +
                '    }\n' +
                '    \n' +
                '    function closeImageModal() {\n' +
                '        document.getElementById(\'image-modal\').style.display = \'none\';\n' +
                '    }\n' +
                '    \n' +
                '    // Set up image upload handlers for each AI type\n' +
                '    document.querySelectorAll(\'.image-upload\').forEach(upload => {\n' +
                '        upload.addEventListener(\'change\', function(event) {\n' +
                '            const files = event.target.files;\n' +
                '            const aiType = event.target.id.split(\'-upload\')[0]; // Get the AI type from the upload id\n' +
                '            const imagesContainer = document.getElementById(`${aiType}-images`);\n' +
                '            \n' +
                '            for (let i = 0; i < files.length; i++) {\n' +
                '                const file = files[i];\n' +
                '                const reader = new FileReader();\n' +
                '                \n' +
                '                reader.onload = function(e) {\n' +
                '                    const img = document.createElement(\'img\');\n' +
                '                    img.src = e.target.result;\n' +
                '                    img.alt = `${aiType} visualization`;\n' +
                '                    img.className = \'findings-image\';\n' +
                '                    img.onclick = function() { openImageModal(this.src); };\n' +
                '                    imagesContainer.appendChild(img);\n' +
                '                };\n' +
                '                \n' +
                '                reader.readAsDataURL(file);\n' +
                '            }\n' +
                '        });\n' +
                '    });\n' +
                '</script>'
            );
            
            codeDisplay.textContent = htmlContent;
        }
    </script>
</body>
</html>
